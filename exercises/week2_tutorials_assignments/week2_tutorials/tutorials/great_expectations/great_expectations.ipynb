{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Expectations\n",
    "[Great Expectations](https://docs.greatexpectations.io/docs/) is a tool for data validation. You can think of this as running unit tests on our data. To gain a first impression of Great Expectations, we recommend taking a look at the [quick-start tutorial](https://docs.greatexpectations.io/docs/tutorials/quickstart/) provided by Great Expectations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.data_context import EphemeralDataContext, FileDataContext\n",
    "from great_expectations.datasource.fluent import BatchRequest\n",
    "from great_expectations.exceptions import DataContextError\n",
    "from great_expectations.expectations.expectation import Expectation\n",
    "from great_expectations.checkpoint.types.checkpoint_result import CheckpointResult\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = Path.cwd()\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the familiar wine quality dataset in the following example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(csv_url, sep=\";\")\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train_df, test_df = train_test_split(data, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate Great Expectations\n",
    "Let's first instantiate an entry point for Great Expectations so we can get started with it. Running the code cell below creates a folder `gx` in your working directory with all things related to working with Great Expectations. \n",
    "\n",
    "To better understand what the code below does, you can go through the following concepts used by Great Expectations [here](https://docs.greatexpectations.io/docs/glossary).\n",
    "- Data Context\n",
    "- Data Source\n",
    "- Data Asset\n",
    "- Batch Request\n",
    "- Expectation and Expectation Suite\n",
    "- Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_datasource_name = \"wine_datasource\"\n",
    "wine_expectation_suite_name = \"wine_expectation_suite\"\n",
    "\n",
    "# Instantiate a Data Context and save it in filesystem.\n",
    "context = gx.get_context(project_root_dir=str(WORKING_DIR))\n",
    "\n",
    "# Connect to data in our wine DataFrame.\n",
    "try:\n",
    "    # Create a new Data Source in the Data Context\n",
    "    datasource = context.sources.add_pandas(name=wine_datasource_name)\n",
    "except DataContextError:\n",
    "    # The Data Source already exists in the Data Context\n",
    "    datasource = context.get_datasource(wine_datasource_name)\n",
    "\n",
    "try:\n",
    "    # Create a new DataFrame Data Asset\n",
    "    training_data_asset = datasource.add_dataframe_asset(name=\"training_data\")\n",
    "except ValueError:\n",
    "    # The Data Asset already exists\n",
    "    training_data_asset = datasource.get_asset(\"training_data\")\n",
    "\n",
    "# Request all data in the training DataFrame as a single batch\n",
    "training_batch_request = training_data_asset.build_batch_request(dataframe=train_df)\n",
    "\n",
    "# Create an Expectation Suite \n",
    "context.add_or_update_expectation_suite(wine_expectation_suite_name)\n",
    "\n",
    "# Create a Validator\n",
    "wine_validator = context.get_validator(\n",
    "    batch_request=training_batch_request,\n",
    "    expectation_suite_name=wine_expectation_suite_name\n",
    ")\n",
    "display(wine_validator.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Expectations\n",
    "After creating a Validator, we can start to define Expectations interactively (other ways exist as well). We can define Expectations by calling the `expect_*` methods of the Validator object. Each method performs two tasks: \n",
    "1) it stores the defined Expectation to the Expectation Suite, \n",
    "2) it also runs the Expectation against the data loaded into the Validator (`train_df` in this case), and returns an `ExpectationValidationResult` object, which is a dictionary holding the test results. This way a user can see if the Expectations they have suggested align with the data loaded into the Validator.\n",
    "\n",
    "Let's define an Expectation to make sure that there is no null value in the target column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = wine_validator.expect_column_values_to_not_be_null(\"quality\")\n",
    "print(f\"Test status: {'Succeeded' if result['success'] else 'failed'}\")\n",
    "print(f\"Expectation: {result['expectation_config']['expectation_type']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Expectation Suite we have configured this far exists only in memory and has to be persisted for future use. Let's save the Expectation Suite into our Data Context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validate new data against the defined Expectations\n",
    "Let's run our newly defined Expectation Suite against the test data. This is done by creating and configuring a [Checkpoint](https://docs.greatexpectations.io/docs/terms/checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create a new DataFrame Data Asset\n",
    "    test_data_asset = datasource.add_dataframe_asset(name=\"test_data\")\n",
    "except ValueError:\n",
    "    # The Data Asset already exists\n",
    "    test_data_asset = datasource.get_asset(\"test_data\")\n",
    "\n",
    "# Request all data in the test DataFrame as a single batch\n",
    "test_batch_request = test_data_asset.build_batch_request(dataframe=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=\"test_checkpoint\",\n",
    "    batch_request=test_batch_request,\n",
    "    expectation_suite_name=wine_expectation_suite_name\n",
    ")\n",
    "checkpoint_result = checkpoint.run(run_name=\"test_run1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.view_validation_result(checkpoint_result)\n",
    "\n",
    "# The result is persisted in the `gx` directory and you can also check the result from gx/uncommitted/data_docs/local_site/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
